---
title: "Multiple linear regression"
author: "Sravani Neelapala"
date: "2023-10-30"
output: html_document
---
```{r }
library(tidyverse)
library(dplyr)
```


```{r }
indata <- read.csv("/Users/eric/Ex12_1_5 (1).csv")
dim(indata)
summary(indata)
head(indata)
```
```{r }
cor(indata[, -1])
```

** Capturing linear relationship if the value of satisfaction is 'zero' means it is a non-linear relationship**

```{r }
indata %>% 
  ggplot(aes(x = Age, y = Satisfaction)) +
  geom_point() + geom_smooth(method = 'lm')
```

** Negative correlation between age and satisfaction, look at the confidence interval and some outliers **

```{r }
pairs(indata[, -1])
```
** Might be a correlation with regressors and there is a reltionship between regressors and response like age and satisfaction, age and anxiety, age and anxiety have + relationship**
```{r }

indata %>%
  ggplot(aes(x = Satisfaction)) +
  geom_histogram(binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)))
```

** We did help(geom_histogram) for the binwidth and approximately look like normal distribution **

```{r }
(lm.fit <- lm(Satisfaction ~ Age + Severity + Surg.Med + Anxiety, data = indata))

```
** prints the output , we need to tackle the correlation between the regressors, age and anxiety have negative correlation, reduce the correlation between the regressors

```{r }
#residual plot
fit_residuals <- lm.fit$residuals %>% as.data.frame()
  fit_residuals %>%
  ggplot (aes(sample = lm.fit$residuals)) + stat_qq(distribution = stats :: qnorm) +
  stat_qq_line() + labs( y = "sample quantiles", x = "theoretical quantiles")  +
  theme(text = element_text(size = 16))  

```

** looks approximately normally distributed, couple of outliers
```{r }
fit_residuals %>%
  ggplot(aes(y = lm.fit$residuals, x = 1:nrow(fit_residuals))) +
  geom_point() + labs(y = "residuals", x = "index") +
  theme(text = element_text(size= 16))
```
** mean = 0, no strong pattern(random distribution)
```{r }
summary(lm.fit)
```
** testing the coefficient is statistically significant or not , surg-med and anxiety are not satistically significant at 0.05 level. It has more than that we need. (No relationship or their contribution is masked by other correlation regressors such that redice that correlation to extracct the regressors)

```{r }

(lm.fit2 <- lm(Satisfaction ~ Age + Severity, data = indata))
summary(lm.fit2)

```
** whole table is significant , R^2 values are close 88 and 89,HO: BO = 0, H1: B1 !=0, reject null hypothesis p value is very less for age 0 is not included int he confidence interval, if we take anxiety the confidence interval includes 0., satistically significantly different from 0 when we see the distribution which shows the relation between response and regressors. (We want P value to be small, Doing hypothesis test each line)

Can do PCA on age, severity, surg-med, anxiety and use PCA as regressors, PCA will be orthogonal to each other and gives cleaner regression analysis

Next example , where response is binary classification checking it fails or not, so we fit a binomial model, glm = generalized linear model and specify binom model, no R^2 method for glm, we have deviance formulation.

diff metrics for class. of linear regression and diff. metrics for class. model(binary data)

surg med and anxiety p value is more shows no statistical significance may be because they get masked by the  relation with other regressors 

Binom distribution for yes or No, we use glm model (logistic regression), we don't check with R^2 but we go with deviation and graph AUC(Area under the curve).









